# Daily ML & Python Revision Notes  
Author: Khyati Sharma  

This file contains conceptual questions for reinforcement to strengthen fundamentals.

---
Q1. What is the difference between Class and Object.Give one real-life example.
=>Class: A blueprint or template.Defines what an object will have (variables + methods).
  Object: A real instance created from the class.It uses the class structure.
Example: Class → Car;Object → myCar, yourCar
Q2️.Why do we use super() in child classes?What problem does it solve?
=>super() is used to:
• Call the parent class constructor
• Reuse parent code
• Avoid rewriting same logic
Without super():
• Parent variables won’t initialize
• Code duplication happens
Q3. Why should private variables (__balance) NOT be accessed directly?What could go wrong if we allow it?
=>Private variables:
• Protect sensitive data
• Prevent accidental changes
• Keep control inside class
If accessed directly:
• Anyone can change balance
• No validation
• Security issues
Q4️. What is the difference between:except, else, finally. When is each executed?
=>except runs=>When error occurs
  else	runs=>When NO error
  finally	runs=>Always (cleanup)
Q5️. What is the difference between:"w" mode,"a" mode,"r" mode.When would you use each?
=>• "r" → read data
  • "w" → create new / overwrite
  • "a" → add without deleting

_____________________
Q1. What does `count_frequency` do?
Creates a dictionary that stores each number and its frequency  
(i.e., how many times it appears in the list).
Q2. Why is `if item in freq` needed?
Because `freq[item] += 1` only works if the key already exists.  
If not, Python raises a `KeyError`.  
So we check first to:
- Increment if exists
- Initialize to 1 if not
Q3. What breaks if we remove the `if`?
On first occurrence of any item,python tries:
freq[item] += 1
Key doesn’t exist → KeyError → program crashes.
q4.One mistake you might make if writing it again
=>getting confused between freq[item] or item[freq]
q5.def add(a,b):
     return a+b
_____________________
Q1 What are features (X)?
=> Features (X) are the input variables (columns) that the model uses to make predictions.
Q2 What is the target (y)?
=>Target (y) is the output variable (column) that we want the model to predict. 
Q3 Why do we split data into train and test?
=> We split data so that the model is evaluated on unseen data, which helps us measure how well it generalizes, not just how well it memorizes. the ratio of train:test is usually 80:20 or 70:30
Q4 What could go wrong if we train and test on the same data? 
=>The model may overfit — it appears to perform well on training data but fails on unseen data.

_____________________
Q1. What is underfitting?
=>this happens when the model underperforms on the training data due to high variance and high bias
Q2. What is overfitting?
=>this happens when the model overperforms in training data due to low bias(little to no error in training data) hand high variance
Q3. Where does linear regression usually fail?
=>linear regression fails when the relationship between the features and target is not linear
Q4. Why can a complex model perform worse on test data?
=>a complex model can perform worse on test data if the mdel has high variance and low bias i.e if the model is overfitted

_____________________
Q1. What problem did linear regression solve?
=>Linear regression solved the problem of memorisation by bringing the concept of generalization.It solves the problem of predicting a continuous value by learning a general relationship between input and output instead of memorizing data points.
Q2. Why did polynomial regression overfit?
=>polynomial regression overfitted when the degree was taken too high which resulted in the formed curve trying to touch almost all data points.the model became too complex for the small dataset, causing it to learn noise instead of true patterns.
Q3. What does random_state actually control?
=>random_state actually controls the randomness in how the test-test split happens every time to ensure code reproducibility and reusability.same train_test_split every time means same input and output elements and same result.helpful for debugging
Q4. One mistake beginners make in ML.
=>trying to get 100% accurary thinking it improves the model performancewhen it actually causes overfitting

_____________________
Q1. What is the difference between:
pd.read_csv("file.csv")
pd.read_csv("file.csv", usecols=["col1","col2"])
Why would you prefer the second one?
 =>the first one reads all columns from the CSV file whereas the second one Reads only specified columns (col1, col2)..i would prefer the second one when i wont be needing every column of the dataset and also because it Saves memory, Faster loading, Cleaner dataframe.
Q2. What does this do?
pd.read_csv("data.csv", na_values=["NA", "N/A", "missing"])
Why is it important for data cleaning?
 =>this Converts "NA", "N/A", "missing" into actual NaN values .It is important Because:
Pandas functions (isnull(), fillna(), dropna()) work only on real NaN.
Prevents: Wrong statistics, Model errors, Garbage data.
Q3.Explain what happens when you use:
chunks = pd.read_csv("big.csv", chunksize=5000)
When is this useful in real projects?
 =>this helps us Loads file in batches of 5000 rows and returns an iterator.This is extremely useful in real projects when dataset is very large (GBs) and doesn't fit in memory.
Q4. What is the purpose of:
git commit --amend
When should you not use it?
 =>it is used to modify last commit, Change message, Add/remove files and Rewrites commit history.
 Should not be used if commit is already pushed or Shared with others(only for local commits)
_____________________
Q1. What’s the difference between a Python dict and JSON?
=> Python dictionary: A native Python data structure that exists only inside Python memory. It uses single quotes and can store any Python object.
   JSON: Text-based data format Used for data exchange (APIs, files). It is language independent and uses double quotes.It Can only store basic types (string, number, list, bool, null)
Q2. How do you safely load a JSON file and handle missing keys?
=>we can safely load a Json file by using df.read_json('path'). to handle missing values we can use df.isnull().sum() to first count the missing values and then we can handle them
Q3. Write a function that flattens nested JSON into a flat dict.
=>import pandas as pd
  def flatten_json_pandas(json_data):
    df = pd.json_normalize(json_data)
    return df
Q4. Explain why APIs usually return JSON and how Python’s requests handles it.
=>Most modern APIs return data in JSON format because: Lightweight, Human readable, Language independent, Easy to parse.
import requests
response = requests.get("API_URL")
data = response.json()
Q5. What’s the difference between a SQL JOIN and filtering with WHERE?
=>WHERE is used to:Filter rows inside same table
  JOIN is used to Combine multiple tables based on common column
_____________________
Q1. Why is EDA performed before building any machine learning model?
=>
Q2. What is the difference between EDA and preprocessing?
=>
Q3. When should you use a histogram vs boxplot vs scatter plot?
=>
Q4. Why should categorical variables not be included directly in a correlation heatmap?
=>
Q5. How does EDA help in choosing the type of model (linear vs non-linear)
=>

______________________
Q1. Why is it important to centralize preprocessing logic in a single module?
=>
Q2. What problems can occur if you scale features unnecessarily?
=>
Q3. Why is .copy() used when modifying pandas DataFrames?
=>
Q4. What is the difference between encoding features and encoding targets?
=>
Q5. How does improper preprocessing lead to data leakage?
=>
______________________
Q1. What assumptions does Linear Regression make about the data?
=>
Q2. Why is feature scaling important for Linear Regression?
=>
Q3. How does Polynomial Regression capture non-linear relationships?
=>
Q4. Why does increasing polynomial degree increase the risk of overfitting?
=>
Q5. When would you prefer Linear Regression over Polynomial Regression?
=>
______________________
What does MAE measure and when is it preferred?

How is MSE different from MAE, and why does it penalize large errors more?

What is RMSE, and why is it often easier to interpret than MSE?

What does a negative R² score indicate?

Why should multiple metrics be used instead of relying on just one?
______________________
How is a classification problem different from a regression problem?

Why did you convert a continuous target into Low / Medium / High categories?

What is the role of stratified train-test split in classification?

Why should the target variable be encoded separately from features?

What are the risks of imbalanced classes in classification tasks?

______________________
Why is Logistic Regression considered a linear classifier?

Why is feature scaling critical for Logistic Regression?

What does the max_iter parameter control?

How does Logistic Regression handle multi-class classification?

Why can Logistic Regression fail to converge on unscaled data?
______________________
Why do Decision Trees not require feature scaling?

What causes Decision Trees to overfit?

How does Random Forest reduce overfitting compared to a single tree?

Why is Random Forest less interpretable than Decision Tree?

When would you prefer a tree-based model over a linear model?

______________________
What does SVM try to maximize when separating classes?

Why is feature scaling mandatory for SVM?

What is the role of the kernel in SVM?

Why is SVM computationally expensive for large datasets?

When is SVM a better choice than Logistic Regression?

______________________
Why is accuracy alone not sufficient for evaluating classification models?

What does macro F1-score indicate?

Why is it important to compare multiple models on the same dataset?

How do you decide between two models with similar accuracy?

Why should model selection consider interpretability vs performance?

______________________
What problem do scikit-learn pipelines solve?

Why is ColumnTransformer useful in pipelines?

How do pipelines prevent preprocessing mistakes during inference?

Why is shared preprocessing better than model-specific preprocessing?

How does clean folder structure improve collaboration and maintainability?

______________________
Why should commits be small and descriptive?

What is the benefit of separating basics and applied projects?

Why should generated files (plots, temp files) be added to .gitignore?

How does modular code help during experimentation?

What signals does a clean GitHub repo send to recruiters?

______________________